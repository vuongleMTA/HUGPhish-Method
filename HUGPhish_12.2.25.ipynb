{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1dabd84-d826-462d-8672-6c50b95672f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: use manual HTML features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import run_ML\n",
    "from sklearn.metrics import f1_score\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2362c08a-bc2b-4b59-952a-9303ecdea868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import gensim\n",
    "import urllib\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from numpy import load, save,  asarray\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29f29055-f291-41fb-8bb2-f0dfa71b1759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = \"E:/Phising URL Detection/Baseline/DLM-main/DLM-main/tmp\"\n",
    "data_dir = \"E:/Phising URL Detection/baseline/HybridDLM-main/HybridDLM-main/dataset_URLs/URLdataset_26.12_html_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a412cfc-46d1-4227-8ed5-7d2ecd92d8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc2vec = gensim.models.doc2vec.Doc2Vec.load(\"E:/Phising URL Detection/Baseline/DLM-main/DLM-main/doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "190a4016-74ab-4e74-946a-7775cde2ac0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import generate_filename, convert, read_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a0e1699-73e3-4864-ac7b-4372b03b94de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def callTag(tag, node):\n",
    "    node_from = node\n",
    "    node = node + 1\n",
    "\n",
    "    for tag in tag.children:\n",
    "        attr_node = 1\n",
    "        if (tag.name is not None):\n",
    "            nodes_list.append(convert([str(node_from), str(node)]))\n",
    "            attr_list.append(str(node) + \",nname,\" + str(tag.name))\n",
    "            attr_list.append(str(node) + \",value,\" + \"\")\n",
    "            for attr in tag.attrs:\n",
    "                nodes_list.append(convert([str(node), str(node) + \"_\" + str(attr_node)]))\n",
    "                attr_list.append(str(node) + \"_\" + str(attr_node) + \",nname,\" + str(attr))\n",
    "                attr_list.append(str(node) + \"_\" + str(attr_node) + \",value,\" + str(tag.get(attr)))\n",
    "                attr_node = attr_node + 1\n",
    "            callTag(tag, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "716dcd3a-17a1-40dd-9e3a-70af987fb029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_udst_inputs(url, rec_id, phishing_flag):\n",
    "    node = 0\n",
    "    f = codecs.open(Path(data_dir + '/' + generate_filename(rec_id)), 'r', encoding='utf-8', errors='ignore')\n",
    "    soup = BeautifulSoup(f)\n",
    "    callTag(soup, node)\n",
    "\n",
    "    nodes_list.pop(0)\n",
    "    attr_list.pop(1)\n",
    "    attr_list.insert(1, '1, value, ' + url)\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(nodes_list)\n",
    "\n",
    "    A = nx.adjacency_matrix(G) # N*N Adjacency matrix\n",
    "\n",
    "    df_features = pd.DataFrame(0.0, index=G.nodes(), columns=['nname', 'value'])\n",
    "\n",
    "    attr_val_list = []\n",
    "    for x in attr_list:\n",
    "        y = x.split(',')\n",
    "        if y[1] == \"value\":\n",
    "            attr_val_list.append(y[2])\n",
    "\n",
    "    for x in attr_list:\n",
    "        y = x.split(',')\n",
    "        test_corpus = list(read_corpus([y[2]], tokens_only=True))\n",
    "        vector = doc2vec.infer_vector(test_corpus[0])\n",
    "        # print(test_corpus[0])\n",
    "\n",
    "        if y[1] == \"nname\":\n",
    "            df_features.loc[y[0]][\"nname\"] = vector\n",
    "\n",
    "        else:\n",
    "            df_features.loc[y[0]][\"value\"] = vector\n",
    "\n",
    "    X = df_features.values # N*d Feature Matrix\n",
    "    # y = to_categorical(phishing_flag, num_classes=2).tolist() # Label\n",
    "    y = phishing_flag\n",
    "\n",
    "    X_ = np.array([np.array(ai, dtype=np.float32) for ai in X.tolist()])\n",
    "\n",
    "    # url_token = url_tokenizer([url])[0]\n",
    "    url_token = None\n",
    "\n",
    "    return X_, A, y, url_token, url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9132d59-ef74-44d2-91aa-e89d9b5fc54d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51996577-859a-466e-a40f-b60f6a51a8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a143c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('URLdataset_13.2_2_final_suf.csv')\n",
    "df['label'] = df['label'].replace({'legitimate': 0, 'phishing': 1})\n",
    "smalldata=df\n",
    "labels=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1191cc9-98c5-44a7-8c0c-29f92121e08d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_id</th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1274</td>\n",
       "      <td>https://www.studiosamo.it/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2352</td>\n",
       "      <td>http://www.redditery.com/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rec_id                         url  label\n",
       "0    1274  https://www.studiosamo.it/      0\n",
       "1    2352   http://www.redditery.com/      0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcd08658-b0b2-44af-8058-95c255eed904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 1496, 1: 735}), 2231)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "counter = collections.Counter(labels)\n",
    "counter, len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a837d-63e3-40cf-afc9-9593072d34e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conventional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cd8d0e0-af10-42b5-9bd9-bced95415a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import extract_features_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb80b3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain': 'www.klikaj.hr',\n",
       " 'num_subdomains': 2,\n",
       " 'contains_ip': 0,\n",
       " 'path_length': 1,\n",
       " 'num_path_segments': 1,\n",
       " 'uses_https': 1,\n",
       " 'file_extension': '',\n",
       " 'count_special_characters': 6,\n",
       " 'count_non_alphanumeric_characters': 6,\n",
       " 'TLD': 'hr',\n",
       " 'count_obfuscated_characters': 0,\n",
       " 'letter_ratio_in_url': 0.7272727272727273,\n",
       " 'digit_ratio_in_url': 0.0,\n",
       " 'count_equals_in_url': 0,\n",
       " 'NoOfAmpersandInURL': 0,\n",
       " 'CharContinuationRate': 0.18181818181818182,\n",
       " 'ratio_obfuscated_characters': 0.0,\n",
       " 'NoOfQMarkInURL': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features_url(\"https://www.klikaj.hr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c999c69c-2338-4ea3-a5df-2bbd10c0dd49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0, fold: 0\n",
      "LightGBM, Fold 0 - F1 Score: 0.8060715, Precision: 0.8113705, Recall: 0.8015354\n",
      "Run: 0, fold: 1\n",
      "LightGBM, Fold 1 - F1 Score: 0.8081386, Precision: 0.8146110, Recall: 0.8028311\n",
      "Run: 0, fold: 2\n",
      "LightGBM, Fold 2 - F1 Score: 0.7816684, Precision: 0.7920805, Recall: 0.7744137\n",
      "Run: 0, fold: 3\n",
      "LightGBM, Fold 3 - F1 Score: 0.8028584, Precision: 0.7999533, Recall: 0.8060617\n",
      "Run: 0, fold: 4\n",
      "LightGBM, Fold 4 - F1 Score: 0.7932360, Precision: 0.8013633, Recall: 0.7874344\n",
      "['LightGBM']\n",
      "F1 Score, Precision, Recall: [[0.7983946 0.8038757 0.7944553]]\n"
     ]
    }
   ],
   "source": [
    "## test on numerical URLs features\n",
    "from utils import extract_numerical_features\n",
    "phish_url = []\n",
    "for link in list(smalldata.iloc[:,1]):\n",
    "    url_features = extract_numerical_features(link)\n",
    "    phish_url.append(list(url_features.values()))\n",
    "run_ML(np.array(phish_url), labels, \"URLdataset13.2\", \"url_manual_numerical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ed85c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7878239600609808\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n_samples = len(smalldata.index)\n",
    "train_idx = list(np.random.choice(list(range(n_samples)), int(0.8*n_samples), replace=False))\n",
    "test_idx = list(set(list(range(n_samples))).difference(set(train_idx)))\n",
    "data_df = np.array(phish_url)\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier(verbose=-1)\n",
    "model.fit(data_df[train_idx], labels[train_idx])\n",
    "y_predict=model.predict(data_df[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79b7fe-f017-4894-a558-ecf95e00c992",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract graph features from URLs for PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2be46503-1dab-4c89-9a14-2859346a62ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8815119367883189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 4))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 4))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(analyzer='char', ngram_range=(1, 4))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "# List of URLs\n",
    "urls = list(smalldata['url'])\n",
    "# Tokenization and N-grams Generation\n",
    "# You can adjust ngram_range to extract different n-grams (e.g., (1, 1) for unigrams, (2, 2) for bigrams, etc.)\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 4)) #5\n",
    "X_counts = vectorizer.fit_transform(urls)\n",
    "# TF-IDF Transformation\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_counts)\n",
    "# Extracted Features\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "X_counts_data = X_counts.toarray() # not necessary\n",
    "# Train lgb\n",
    "model_lgb = lgb.LGBMClassifier(verbose=-1)\n",
    "model_lgb.fit(X_counts_data[train_idx], labels[train_idx])\n",
    "y_predict=model_lgb.predict(X_counts_data[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))\n",
    "feature_imp_gain = pd.DataFrame(sorted(zip(model_lgb.booster_.feature_importance(importance_type='gain'),\n",
    "                                           feature_names), reverse=True), columns=['Value', 'Feature'])\n",
    "feature_imp_split = pd.DataFrame(sorted(zip(model_lgb.booster_.feature_importance(importance_type='split'),\n",
    "                                            feature_names), reverse=True), columns=['Value', 'Feature'])\n",
    "top_ngrams_features = list(set(list(feature_imp_gain.iloc[:200,1]) + list(feature_imp_split.iloc[:200,1])))\n",
    "cv = CountVectorizer(analyzer='char', ngram_range=(1, 4))\n",
    "cv.fit(top_ngrams_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ec2dd2e-e01b-4b9d-bb3e-f8a36ec4e787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_feature_CountVectorizer(model, url):\n",
    "    return model.transform([url]).toarray().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ddb6f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0, fold: 0\n",
      "LightGBM, Fold 0 - F1 Score: 0.8896670, Precision: 0.8875771, Recall: 0.8918725\n",
      "Run: 0, fold: 1\n",
      "LightGBM, Fold 1 - F1 Score: 0.8962911, Precision: 0.9045304, Recall: 0.8893836\n",
      "Run: 0, fold: 2\n",
      "LightGBM, Fold 2 - F1 Score: 0.8898642, Precision: 0.8911486, Recall: 0.8886278\n",
      "Run: 0, fold: 3\n",
      "LightGBM, Fold 3 - F1 Score: 0.9097058, Precision: 0.9097058, Recall: 0.9097058\n",
      "Run: 0, fold: 4\n",
      "LightGBM, Fold 4 - F1 Score: 0.8694144, Precision: 0.8840336, Recall: 0.8595280\n",
      "['LightGBM']\n",
      "F1 Score, Precision, Recall: [[0.8909885 0.8953991 0.8878235]]\n"
     ]
    }
   ],
   "source": [
    "# extract countvectorizer feature of all URLs\n",
    "phish_url_countvectorizer = []\n",
    "for link in list(smalldata.iloc[:,1]):\n",
    "    url_features = extract_feature_CountVectorizer(cv,link)\n",
    "    phish_url_countvectorizer.append(url_features)\n",
    "run_ML(np.array(phish_url_countvectorizer), labels, \"URLdataset13.2\", \"ngramURLfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2aff0302-b0ae-4da5-9f44-171a1010f762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import ConnectionError\n",
    "import traceback\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10ff57d-4c7d-452c-980a-9e64ab31812b",
   "metadata": {},
   "source": [
    "# Run HTML features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d84036c-da1d-4c9d-99e7-d35fd9548004",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Idea: Combine with manual features from HTMLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1a612b8-8a9b-4092-bb92-edcdcf2e2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML offline\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "# import whois\n",
    "from urllib.parse import urlparse\n",
    "from collections import Counter\n",
    "\n",
    "# Function to parse HTML content from a URL\n",
    "def get_html_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise error if the response is bad\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract HTML structure features\n",
    "def extract_structure_features(soup):\n",
    "    features = {}\n",
    "    \n",
    "    features['num_divs'] = len(soup.find_all('div'))\n",
    "    features['num_scripts'] = len(soup.find_all('script'))\n",
    "    features['num_forms'] = len(soup.find_all('form'))\n",
    "    features['num_links'] = len(soup.find_all('a'))\n",
    "    features['num_iframes'] = len(soup.find_all('iframe'))\n",
    "    \n",
    "    # Text to HTML ratio\n",
    "    text_length = len(soup.get_text())\n",
    "    html_length = len(str(soup))\n",
    "    features['text_to_html_ratio'] = text_length / html_length if html_length > 0 else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Function to extract text-based features\n",
    "def extract_text_features(soup):\n",
    "    \n",
    "    features = {}\n",
    "\n",
    "    # Title tag content\n",
    "    title = soup.title.string if soup.title and soup.title.string else ''\n",
    "    features['title_length'] = len(title)\n",
    "\n",
    "    # Visible text length\n",
    "    visible_text = soup.get_text() if soup else ''\n",
    "    features['visible_text_length'] = len(visible_text)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to extract link-based features\n",
    "# def extract_link_features(soup, base_url):\n",
    "#     features = {}\n",
    "    \n",
    "#     all_links = soup.find_all('a', href=True)\n",
    "#     internal_links = [link for link in all_links if urlparse(link['href']).netloc == urlparse(base_url).netloc]\n",
    "#     external_links = [link for link in all_links if urlparse(link['href']).netloc != urlparse(base_url).netloc]\n",
    "    \n",
    "#     features['num_internal_links'] = len(internal_links)\n",
    "#     features['num_external_links'] = len(external_links)\n",
    "    \n",
    "#     return features\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def extract_link_features(soup, base_url):\n",
    "    features = {}\n",
    "    \n",
    "    try:\n",
    "        all_links = soup.find_all('a', href=True)\n",
    "        internal_links = []\n",
    "        external_links = []\n",
    "        \n",
    "        for link in all_links:\n",
    "            href = link['href']\n",
    "            try:\n",
    "                parsed_href = urlparse(href)\n",
    "                parsed_base = urlparse(base_url)\n",
    "                \n",
    "                if parsed_href.netloc == parsed_base.netloc:\n",
    "                    internal_links.append(href)\n",
    "                else:\n",
    "                    external_links.append(href)\n",
    "            except ValueError:\n",
    "                continue  # Skip invalid links\n",
    "        \n",
    "        features['num_internal_links'] = len(internal_links)\n",
    "        features['num_external_links'] = len(external_links)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting link features: {e}\")\n",
    "        features['num_internal_links'] = 0\n",
    "        features['num_external_links'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# Function to extract JavaScript-based features\n",
    "def extract_js_features(soup):\n",
    "    features = {}\n",
    "    \n",
    "    script_tags = soup.find_all('script')\n",
    "    features['num_js_files'] = len(script_tags)\n",
    "    \n",
    "    # Suspicious JavaScript patterns\n",
    "    suspicious_js_patterns = ['eval', 'document.write', 'window.location']\n",
    "    features['suspicious_js_count'] = sum(\n",
    "        any(p in script.get_text() for p in suspicious_js_patterns) for script in script_tags)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Function to extract all features from a URL\n",
    "def extract_features(url, rec_id):\n",
    "#     html_content = get_html_content(url)\n",
    "#     if not html_content:\n",
    "#         return None\n",
    "    \n",
    "#     soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    f = codecs.open(Path(data_dir + '/' + generate_filename(rec_id)), 'r', encoding='utf-8', errors='ignore')\n",
    "    soup = BeautifulSoup(f)\n",
    "    \n",
    "    # Extract all feature sets\n",
    "    structure_features = extract_structure_features(soup)\n",
    "    text_features = extract_text_features(soup)\n",
    "    link_features = extract_link_features(soup, url)\n",
    "    js_features = extract_js_features(soup)\n",
    "    # domain_features = extract_domain_features(url)\n",
    "    \n",
    "    # Combine all features into a single dictionary\n",
    "    features = {**structure_features, **text_features, **link_features, **js_features}\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c56de6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_divs': 426,\n",
       " 'num_scripts': 7,\n",
       " 'num_forms': 0,\n",
       " 'num_links': 121,\n",
       " 'num_iframes': 0,\n",
       " 'text_to_html_ratio': 0.23880716044000447,\n",
       " 'title_length': 24,\n",
       " 'visible_text_length': 44917,\n",
       " 'num_internal_links': 39,\n",
       " 'num_external_links': 79,\n",
       " 'num_js_files': 7,\n",
       " 'suspicious_js_count': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(\"http://vamoaestudiarmedicina.blogspot.com/\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e260c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7605"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldata.iloc[159,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcbde0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://zpr.io/FxiKGNiWpd3T'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldata.iloc[159,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90da06a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,"
     ]
    }
   ],
   "source": [
    "manual_html_features = []\n",
    "for idx in range(len(smalldata.index)):\n",
    "    url = smalldata.iloc[idx, 1]\n",
    "    print(idx,end=',')\n",
    "    rec_id = smalldata.iloc[idx, 0]\n",
    "    features = extract_features(url, rec_id)\n",
    "    manual_html_features.append(list(features.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73f92e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Lưu vào file pickle\n",
    "with open(\"manual_html_features_URLdataset13.2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(manual_html_features, f)\n",
    "\n",
    "# Mở file pickle và nạp dữ liệu vào biến manual_html_features\n",
    "# with open(\"manual_html_features_URLdataset13.2.pkl\", \"rb\") as f:\n",
    "#     manual_html_features_13.2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab8ce0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2231"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manual_html_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c52a8f88-2428-405c-936c-bf0e8e588ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0, fold: 0\n",
      "LightGBM, Fold 0 - F1 Score: 0.8258388, Precision: 0.8235562, Recall: 0.8283076\n",
      "Run: 0, fold: 1\n",
      "LightGBM, Fold 1 - F1 Score: 0.8079793, Precision: 0.8275653, Recall: 0.7956164\n",
      "Run: 0, fold: 2\n",
      "LightGBM, Fold 2 - F1 Score: 0.8579392, Precision: 0.8647378, Recall: 0.8523317\n",
      "Run: 0, fold: 3\n",
      "LightGBM, Fold 3 - F1 Score: 0.8524953, Precision: 0.8448440, Recall: 0.8622484\n",
      "Run: 0, fold: 4\n",
      "LightGBM, Fold 4 - F1 Score: 0.8538467, Precision: 0.8491075, Recall: 0.8603147\n",
      "['LightGBM']\n",
      "F1 Score, Precision, Recall: [[0.8396199 0.8419622 0.8397638]]\n"
     ]
    }
   ],
   "source": [
    "run_ML(np.array(manual_html_features), labels, \"URLdataset13.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90088b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlhtml_manual_features = np.concatenate([phish_url, manual_html_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b67482b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngramUrl_manualHtml_features = np.concatenate([phish_url_countvectorizer, manual_html_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5e5a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0, fold: 0\n",
      "LightGBM, Fold 0 - F1 Score: 0.8845352, Precision: 0.8824732, Recall: 0.8867121\n",
      "Run: 0, fold: 1\n",
      "LightGBM, Fold 1 - F1 Score: 0.8962911, Precision: 0.9045304, Recall: 0.8893836\n",
      "Run: 0, fold: 2\n",
      "LightGBM, Fold 2 - F1 Score: 0.8998243, Precision: 0.9142432, Recall: 0.8891873\n",
      "Run: 0, fold: 3\n",
      "LightGBM, Fold 3 - F1 Score: 0.9035123, Precision: 0.8969601, Recall: 0.9111707\n",
      "Run: 0, fold: 4\n",
      "LightGBM, Fold 4 - F1 Score: 0.9071505, Precision: 0.9083158, Recall: 0.9060315\n",
      "['LightGBM']\n",
      "F1 Score, Precision, Recall: [[0.8982627 0.9013045 0.896497 ]]\n"
     ]
    }
   ],
   "source": [
    "run_ML(np.array(urlhtml_manual_features), labels, \"URLdataset132\", \"urlhtml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a0af2-dbb5-4486-827e-6701f53505c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create dataset class for PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e55784ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "566cd482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,"
     ]
    }
   ],
   "source": [
    "if True: #don't delete this\n",
    "    graphs = []\n",
    "    labels_list = []\n",
    "    for i in range(0,len(smalldata.index)):\n",
    "    # for i in range(2):\n",
    "        nodes_list = []\n",
    "        attr_list = []\n",
    "        print(i, end = ',')\n",
    "        X, A, y, X_A, _ = get_udst_inputs(smalldata.iloc[i, 1], smalldata.iloc[i, 0], smalldata.iloc[i, 2])\n",
    "\n",
    "        child_id, source_id = A.nonzero()\n",
    "        edge_index = torch.tensor([source_id,\n",
    "                                   child_id], dtype=torch.long)\n",
    "        x = torch.tensor(X, dtype=torch.float)\n",
    "        y = torch.tensor([labels[i]], dtype=torch.int64)\n",
    "        data = Data(x=x, edge_index=edge_index, y = y)\n",
    "        graphs.append(data)\n",
    "        labels_list.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a80b5f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2231"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23e24a6b-5a65-41f7-968a-5c7d01e6f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"graph_html_13.2_final_suf\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(graphs, fp)\n",
    "with open(\"graph_html_labels_13.2_final_suf\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(labels_list, fp)\n",
    "    \n",
    "# with open(\"graph_html\", \"rb\") as fp:   # Unpickling\n",
    "#     graphs = pickle.load(fp)\n",
    "# with open(\"graph_html_labels\", \"rb\") as fp:   # Unpickling\n",
    "#     labels_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "989171c6-277c-434e-83a9-b618267e54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train freq:  [1496, 735]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train freq: \", [len(list(group)) for key, group in groupby(sorted(labels_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95aeabfb-454b-4984-a875-a6104537382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "class GraphClassificationDataset(Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "        # self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        # label = self.labels[idx]\n",
    "        return graph\n",
    "    \n",
    "    def get(): pass\n",
    "\n",
    "    def len(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e607ec88-7a07-476f-a644-96c494bed7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphClassificationDataset(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "56107391-7b84-4614-b367-81d5d04b0545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: GraphClassificationDataset(2231):\n",
      "====================\n",
      "Number of graphs: 2231\n",
      "Number of features: 2\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c34344fc-0487-4632-8e65-676e88e892c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = dataset[:int(0.8*n_samples)]\n",
    "# test_dataset = dataset[int(0.8*n_samples):]\n",
    "train_dataset = [dataset[idx] for idx in train_idx]\n",
    "test_dataset = [dataset[idx] for idx in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb440b6e-47cc-4b2e-a554-e6ff6fec2bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1784, 447)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "acf1c066-f7b9-4f66-8260-330c70c40068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729a4ea-1ac8-4ea5-97ef-8fedbbf3311a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build and train PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b7fba98-98b6-4a62-8917-8a5d10f2d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "        self.linconcat = Linear(2*hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a874e18f-2693-4626-a66c-15952318b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train F1: 0.4124, Test F1: 0.4148\n",
      "Epoch: 010, Train F1: 0.4227, Test F1: 0.4402\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        # print(data.x.shape)\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    # for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "    #     out = model(data.x, data.edge_index, data.batch)  \n",
    "    #     pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    #     correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    # return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        true_labels += data.y.tolist()\n",
    "        pred_labels += pred.tolist()\n",
    "        # print(pred_labels)\n",
    "    return f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "for epoch in range(0, 20):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train F1: {train_acc:.4f}, Test F1: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f69e8d-74fc-4369-aabb-e8d4b723a1ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GNN for dim. reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00edafd-7277-4644-b563-2910d441a5ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Net 1: 0.87, 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c74a0be3-48cf-4b24-9c56-48826ab199d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "class GCNdimReduce(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCNdimReduce, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def dimReduce(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x = x.relu()\n",
    "        # x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # # 3. Apply a final classifier\n",
    "        x = self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9cc7d-4f1a-476f-ab19-2643c4a404e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Net 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a751eb5f-e5eb-4450-8ba0-c65ef45d9486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "class GCNdimReduceV2(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCNdimReduceV2, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "       \n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # 3. Apply a final classifier\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def dimReduce(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717a4558-f031-44f1-9a1d-4780580cae3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bcd6b977-ad35-43eb-adbc-d401261e6d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train F1: 0.4041, Test F1: 0.3902\n",
      "Epoch: 001, Train F1: 0.4041, Test F1: 0.3902\n",
      "Epoch: 002, Train F1: 0.4041, Test F1: 0.3902\n",
      "Epoch: 003, Train F1: 0.4041, Test F1: 0.3902\n",
      "Epoch: 004, Train F1: 0.4041, Test F1: 0.3902\n",
      "Epoch: 005, Train F1: 0.4041, Test F1: 0.3902\n",
      "Epoch: 006, Train F1: 0.4041, Test F1: 0.3902\n",
      "Epoch: 007, Train F1: 0.4041, Test F1: 0.3902\n",
      "Epoch: 008, Train F1: 0.4079, Test F1: 0.3969\n",
      "Epoch: 009, Train F1: 0.4522, Test F1: 0.4418\n"
     ]
    }
   ],
   "source": [
    "n_hidden_channels = 16\n",
    "model = GCNdimReduce(hidden_channels=n_hidden_channels)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        # print(data.x.shape)\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        true_labels += data.y.tolist()\n",
    "        pred_labels += pred.tolist()\n",
    "    return f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train F1: {train_acc:.4f}, Test F1: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a05648-8619-48c4-9f1f-32100030cb2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b89c35c1-ac25-430e-b212-87492087a072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(all_data_loader, train_loader, test_loader, n_hidden_channels = 16, n_epoch=1, lr=0.001):\n",
    "    # n_hidden_channels = 16\n",
    "    model = GCNdimReduce(hidden_channels=n_hidden_channels)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "\n",
    "        for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "            # print(data.x.shape)\n",
    "            out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "            loss = criterion(out, data.y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "    def test(loader):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "            out = model(data.x, data.edge_index, data.batch)  \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "            true_labels += data.y.tolist()\n",
    "            pred_labels += pred.tolist()\n",
    "        return f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "    for epoch in range(0, n_epoch):\n",
    "        train()\n",
    "        train_acc = test(train_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if epoch % 1 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Train F1: {train_acc:.4f}, Test F1: {test_acc:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    dim_vec = torch.empty((0, n_hidden_channels), dtype=torch.float32)\n",
    "    for data in all_data_loader:\n",
    "        dim_x = model.dimReduce(data.x, data.edge_index, data.batch)\n",
    "        dim_vec = torch.cat((dim_vec, dim_x), 0)\n",
    "    return (dim_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ac5bad79-d5d8-46ea-9935-52c6050c7a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train F1: 0.4041, Test F1: 0.3902\n"
     ]
    }
   ],
   "source": [
    "all_data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "dim_vec = train_model(all_data_loader, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "53c3fadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2231"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "420834c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir=\"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c61c6-f8fa-4c06-999f-576892f31bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runHUGPHISH(train_idx, test_idx):\n",
    "    # stack_GNNs_graph = np.concatenate((np.array(phish_url_vectorizer), hyperlink_features),axis=1)\n",
    "    stack_GNNs_graph = np.array(ngramUrl_manualHtml_features)\n",
    "    for i in range(10):\n",
    "        np.random.seed(i) \n",
    "        # train_idx_new = list(np.random.choice(list(range(n_samples)), int(0.8*n_samples), replace=False))\n",
    "        # train_idx_new = list(set(train_idx_new).difference(test_idx))\n",
    "        train_idx_new = list(np.random.choice(train_idx, int(0.8*len(train_idx)), replace=False))\n",
    "        print(train_idx_new[:5])\n",
    "        train_dataset_new = [dataset[idx] for idx in train_idx_new]\n",
    "        train_loader_new = DataLoader(train_dataset_new, batch_size=8, shuffle=True)\n",
    "        # test_dataset = [dataset[idx] for idx in test_idx]\n",
    "        # test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "        n_hidden_channels = 6\n",
    "        n_epoch = 1\n",
    "        dim_vec_new = train_model(all_data_loader, train_loader_new, test_loader, n_hidden_channels, n_epoch)\n",
    "        stack_GNNs_graph = np.concatenate((stack_GNNs_graph, dim_vec_new.detach().numpy()),axis=1)\n",
    "    \n",
    "    model_lgb2 = lgb.LGBMClassifier(verbose=-1)\n",
    "    model_lgb2.fit(stack_GNNs_graph[train_idx], labels[train_idx])\n",
    "    y_predict=model_lgb2.predict(stack_GNNs_graph[test_idx]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c622dfbd-432c-4d04-9226-9d80fc03684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2027, 71, 1034, 862, 1603]\n",
      "Epoch: 000, Train F1: 0.4012, Test F1: 0.3902\n",
      "[772, 829, 161, 478, 1425]\n",
      "Epoch: 000, Train F1: 0.4081, Test F1: 0.3902\n",
      "[217, 1010, 1226, 2032, 1511]\n",
      "Epoch: 000, Train F1: 0.4019, Test F1: 0.3902\n",
      "[1050, 539, 246, 519, 1837]\n",
      "Epoch: 000, Train F1: 0.4052, Test F1: 0.3902\n",
      "[743, 2197, 2199, 1132, 241]\n",
      "Epoch: 000, Train F1: 0.4044, Test F1: 0.3902\n",
      "[440, 1030, 1419, 583, 143]\n",
      "Epoch: 000, Train F1: 0.4032, Test F1: 0.3902\n",
      "[1503, 2042, 1942, 1276, 838]\n",
      "Epoch: 000, Train F1: 0.3999, Test F1: 0.3902\n",
      "[825, 762, 1851, 1108, 1515]\n",
      "Epoch: 000, Train F1: 0.4037, Test F1: 0.3902\n",
      "[747, 1993, 561, 1282, 169]\n",
      "Epoch: 000, Train F1: 0.4044, Test F1: 0.3902\n",
      "[2119, 1293, 1529, 309, 806]\n",
      "Epoch: 000, Train F1: 0.4049, Test F1: 0.3902\n",
      "0.9100813883316208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>predict_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      true_label  pred_label  predict_proba\n",
       "3              0           0       0.000390\n",
       "7              0           0       0.000081\n",
       "2059           0           0       0.032668\n",
       "2065           1           1       0.998089\n",
       "2067           1           1       0.998608\n",
       "...          ...         ...            ...\n",
       "2036           1           1       0.999522\n",
       "2037           1           1       0.975015\n",
       "2040           1           1       0.919113\n",
       "2043           0           0       0.057086\n",
       "2046           0           0       0.005377\n",
       "\n",
       "[447 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runHUGPHISH(train_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b6dac78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "[1271, 1188, 1498, 1214, 1794]\n",
      "Epoch: 000, Train F1: 0.4024, Test F1: 0.3902\n",
      "[1941, 1081, 380, 136, 2146]\n",
      "Epoch: 000, Train F1: 0.3948, Test F1: 0.3902\n",
      "[784, 649, 644, 1012, 1370]\n",
      "Epoch: 000, Train F1: 0.3987, Test F1: 0.3902\n",
      "[782, 1123, 2206, 978, 456]\n",
      "Epoch: 000, Train F1: 0.3994, Test F1: 0.3902\n",
      "[859, 2187, 327, 1206, 1331]\n",
      "Epoch: 000, Train F1: 0.4004, Test F1: 0.3902\n",
      "[152, 1848, 1597, 804, 1805]\n",
      "Epoch: 000, Train F1: 0.4014, Test F1: 0.3902\n",
      "[1808, 830, 113, 177, 888]\n",
      "Epoch: 000, Train F1: 0.4019, Test F1: 0.3902\n",
      "[81, 356, 1392, 583, 999]\n",
      "Epoch: 000, Train F1: 0.3992, Test F1: 0.3902\n",
      "[1963, 244, 1932, 1912, 2100]\n",
      "Epoch: 000, Train F1: 0.4012, Test F1: 0.3902\n",
      "[1917, 378, 526, 516, 779]\n",
      "Epoch: 000, Train F1: 0.3974, Test F1: 0.3902\n",
      "0.9000117730162468\n",
      "Run:  0 , fold:  1\n",
      "[1253, 1174, 1472, 1200, 1783]\n",
      "Epoch: 000, Train F1: 0.4057, Test F1: 0.3902\n",
      "[1937, 1059, 382, 137, 1705]\n",
      "Epoch: 000, Train F1: 0.4023, Test F1: 0.3902\n",
      "[754, 624, 621, 994, 1354]\n",
      "Epoch: 000, Train F1: 0.4010, Test F1: 0.3902\n",
      "[1954, 2008, 1374, 1229, 645]\n",
      "Epoch: 000, Train F1: 0.4043, Test F1: 0.3902\n",
      "[834, 2192, 329, 1190, 1322]\n",
      "Epoch: 000, Train F1: 0.4025, Test F1: 0.3902\n",
      "[155, 1920, 2132, 775, 1107]\n",
      "Epoch: 000, Train F1: 0.4023, Test F1: 0.3902\n",
      "[78, 1403, 131, 468, 1953]\n",
      "Epoch: 000, Train F1: 0.4005, Test F1: 0.3902\n",
      "[576, 163, 1933, 1591, 2073]\n",
      "Epoch: 000, Train F1: 0.4013, Test F1: 0.3902\n",
      "[1466, 248, 1926, 1372, 1367]\n",
      "Epoch: 000, Train F1: 0.4023, Test F1: 0.3902\n",
      "[1907, 380, 509, 499, 749]\n",
      "Epoch: 000, Train F1: 0.3972, Test F1: 0.3902\n",
      "0.9118474595977213\n",
      "Run:  0 , fold:  2\n",
      "[1267, 1183, 1475, 1209, 1763]\n",
      "Epoch: 000, Train F1: 0.4028, Test F1: 0.3902\n",
      "[1926, 1069, 373, 138, 1687]\n",
      "Epoch: 000, Train F1: 0.4028, Test F1: 0.3902\n",
      "[765, 635, 632, 1005, 1367]\n",
      "Epoch: 000, Train F1: 0.4000, Test F1: 0.3902\n",
      "[1943, 1998, 1382, 1242, 658]\n",
      "Epoch: 000, Train F1: 0.4008, Test F1: 0.3902\n",
      "[841, 2196, 314, 1202, 1333]\n",
      "Epoch: 000, Train F1: 0.3975, Test F1: 0.3902\n",
      "[150, 1913, 2125, 790, 1113]\n",
      "Epoch: 000, Train F1: 0.4065, Test F1: 0.3902\n",
      "[77, 1410, 132, 468, 1942]\n",
      "Epoch: 000, Train F1: 0.4038, Test F1: 0.3902\n",
      "[583, 158, 1923, 1581, 2060]\n",
      "Epoch: 000, Train F1: 0.4013, Test F1: 0.3902\n",
      "[1467, 242, 1917, 1380, 1376]\n",
      "Epoch: 000, Train F1: 0.3997, Test F1: 0.3902\n",
      "[1904, 370, 516, 505, 758]\n",
      "Epoch: 000, Train F1: 0.4003, Test F1: 0.3902\n",
      "0.9098888764171064\n",
      "Run:  0 , fold:  3\n",
      "[1275, 1180, 1485, 1208, 1782]\n",
      "Epoch: 000, Train F1: 0.3987, Test F1: 0.3902\n",
      "[1938, 1060, 383, 136, 1709]\n",
      "Epoch: 000, Train F1: 0.3997, Test F1: 0.3902\n",
      "[774, 633, 629, 999, 1365]\n",
      "Epoch: 000, Train F1: 0.4000, Test F1: 0.3902\n",
      "[1951, 2009, 1384, 1245, 654]\n",
      "Epoch: 000, Train F1: 0.3995, Test F1: 0.3902\n",
      "[851, 2194, 320, 1199, 1331]\n",
      "Epoch: 000, Train F1: 0.4015, Test F1: 0.3902\n",
      "[151, 1922, 2128, 795, 1107]\n",
      "Epoch: 000, Train F1: 0.3985, Test F1: 0.3902\n",
      "[70, 1422, 130, 479, 1950]\n",
      "Epoch: 000, Train F1: 0.3992, Test F1: 0.3902\n",
      "[579, 159, 1934, 1605, 2071]\n",
      "Epoch: 000, Train F1: 0.3985, Test F1: 0.3902\n",
      "[1478, 245, 1926, 1382, 1377]\n",
      "Epoch: 000, Train F1: 0.3957, Test F1: 0.3902\n",
      "[1910, 382, 522, 513, 768]\n",
      "Epoch: 000, Train F1: 0.3990, Test F1: 0.3902\n",
      "0.9063025210084033\n",
      "Run:  0 , fold:  4\n",
      "[1247, 1165, 1465, 1189, 1765]\n",
      "Epoch: 000, Train F1: 0.4075, Test F1: 0.3902\n",
      "[1924, 1052, 371, 125, 1691]\n",
      "Epoch: 000, Train F1: 0.4023, Test F1: 0.3902\n",
      "[743, 615, 611, 986, 1351]\n",
      "Epoch: 000, Train F1: 0.4035, Test F1: 0.3902\n",
      "[1938, 1996, 1368, 1221, 636]\n",
      "Epoch: 000, Train F1: 0.4043, Test F1: 0.3902\n",
      "[825, 2192, 313, 1182, 1312]\n",
      "Epoch: 000, Train F1: 0.4030, Test F1: 0.3902\n",
      "[143, 1902, 2119, 766, 1092]\n",
      "Epoch: 000, Train F1: 0.4043, Test F1: 0.3902\n",
      "[68, 1402, 119, 457, 1937]\n",
      "Epoch: 000, Train F1: 0.4050, Test F1: 0.3902\n",
      "[563, 154, 1919, 1583, 2061]\n",
      "Epoch: 000, Train F1: 0.4045, Test F1: 0.3902\n",
      "[1459, 239, 1909, 1366, 1361]\n",
      "Epoch: 000, Train F1: 0.4025, Test F1: 0.3902\n",
      "[1890, 370, 499, 490, 737]\n",
      "Epoch: 000, Train F1: 0.4005, Test F1: 0.3902\n",
      "0.9243600474869658\n"
     ]
    }
   ],
   "source": [
    "n_loops = 1; n_folds = 5;\n",
    "base_dir = 'results'\n",
    "approach = 'HUGPhish'\n",
    "dataset1 = 'URLdataset13.2'\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "for i in range(n_loops):\n",
    "    cv = KFold(n_splits=n_folds, shuffle=True, random_state = i)\n",
    "    # print(\"Use stratifired fold\")\n",
    "    # cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state = i)\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(smalldata)):\n",
    "        path_dir = base_dir +'/' + dataset1 + '_run_'+str(i)+'_'+ 'fold_'+str(fold)+'_'+approach\n",
    "        print('Run: ', i, ', fold: ', fold)\n",
    "        # X_train = X[train_idx]\n",
    "        # X_test = X[test_idx]\n",
    "        # y_train = y[train_idx]\n",
    "        # y_test = y[test_idx]\n",
    "       \n",
    "        df = runHUGPHISH(train_idx, test_idx)\n",
    "        path_dir = base_dir +'/' + dataset1 + '_run_'+str(i)+'_'+ 'fold_'+str(fold)+'_'+approach\n",
    "        df.to_csv(path_dir + '_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphish_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
